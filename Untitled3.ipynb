{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPpfuYWXt/KS71KQAaA3RI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gunasekar13/PySpark/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_rabW_fYBwD",
        "outputId": "f0f0b5a4-717d-4ab8-d281-1199fd5903bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 51 kB/s \n",
            "\u001b[?25hCollecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 49.3 MB/s \n",
            "\u001b[?25h  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 54.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=673a2dbb969de7caa7772ee2df510d2088cf6eabbaa11963df44f3d7b32e8ae0\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "aLEZeCp2xrC5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('test_spark').getOrCreate()"
      ],
      "metadata": {
        "id": "m2do_yxEx3B4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word count program in pyspark**"
      ],
      "metadata": {
        "id": "sSE9uvalTwXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Create RDD using parallelize**"
      ],
      "metadata": {
        "id": "d1vaON4WUBrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=['one','six','Sixteen','nine','two','one','Sixteen','nine','two','three']\n",
        "word_count_rdd1=spark.sparkContext.parallelize(data)"
      ],
      "metadata": {
        "id": "k2v2ekF2Tv1a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Count word each**"
      ],
      "metadata": {
        "id": "M1Qz7KuhVjD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_rdd2=word_count_rdd1.map(lambda x:(x,1))"
      ],
      "metadata": {
        "id": "KRWMSv7IVqAK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***#Mearge the same word count ***"
      ],
      "metadata": {
        "id": "wCsXkzP-WIre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge_rdd=word_count_rdd2.reduceByKey(lambda x,y:x+y)"
      ],
      "metadata": {
        "id": "JdrPbac_WOum"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#sort the rdd based on counts**"
      ],
      "metadata": {
        "id": "JW8d1gZwW4jX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_rdd=merge_rdd.sortBy(lambda x:x[1],ascending=True).collect()"
      ],
      "metadata": {
        "id": "viO1BAlnXL3Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#how to see the RDD value**"
      ],
      "metadata": {
        "id": "QkbD6a8SVBt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word,count in count_rdd:\n",
        "  print('{},{}'.format(word,count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0RlItZcVHyH",
        "outputId": "14b54bad-a1d9-40ce-bbfc-b157086a25a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "three,1\n",
            "six,1\n",
            "Sixteen,2\n",
            "two,2\n",
            "one,2\n",
            "nine,2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Conver RDD to Dataframe**"
      ],
      "metadata": {
        "id": "Aap1DfvAXstj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=merge_rdd.toDF()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwuluIoRXyY0",
        "outputId": "de0a1727-08c9-4d1d-d0ee-65fa343e70cc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|     _1| _2|\n",
            "+-------+---+\n",
            "|Sixteen|  2|\n",
            "|    two|  2|\n",
            "|  three|  1|\n",
            "|    one|  2|\n",
            "|    six|  1|\n",
            "|   nine|  2|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**### Chage the Column Names**"
      ],
      "metadata": {
        "id": "kCBO1o24YDbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.withColumnRenamed('_1','word').withColumnRenamed('_2','count')\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7ujcxdUbpV1",
        "outputId": "04bbe8fc-b00c-4043-a1f9-fc641fd7369e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|   word|count|\n",
            "+-------+-----+\n",
            "|Sixteen|    2|\n",
            "|    two|    2|\n",
            "|  three|    1|\n",
            "|    one|    2|\n",
            "|    six|    1|\n",
            "|   nine|    2|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge the two Column**"
      ],
      "metadata": {
        "id": "kPXZy5vxb6il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "df.withColumn('word_count',expr('word||\",\"||count')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EqEYq-Ub5hW",
        "outputId": "f2e9d82d-4e90-43d6-fbf7-ea6b7822fb13"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----------+\n",
            "|   word|count|word_count|\n",
            "+-------+-----+----------+\n",
            "|Sixteen|    2| Sixteen,2|\n",
            "|    two|    2|     two,2|\n",
            "|  three|    1|   three,1|\n",
            "|    one|    2|     one,2|\n",
            "|    six|    1|     six,1|\n",
            "|   nine|    2|    nine,2|\n",
            "+-------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Repaet the word twice**"
      ],
      "metadata": {
        "id": "qW9rvzMYceMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import repeat\n",
        "df.withColumn('word_repeat',repeat('word',2)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0L2oxthckPL",
        "outputId": "d6abcec3-607c-468b-f6af-01eee21c4acb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+--------------+\n",
            "|   word|count|   word_repeat|\n",
            "+-------+-----+--------------+\n",
            "|Sixteen|    2|SixteenSixteen|\n",
            "|    two|    2|        twotwo|\n",
            "|  three|    1|    threethree|\n",
            "|    one|    2|        oneone|\n",
            "|    six|    1|        sixsix|\n",
            "|   nine|    2|      ninenine|\n",
            "+-------+-----+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**##lpad and RPad**"
      ],
      "metadata": {
        "id": "j8h30qkWc3Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lpad,rpad"
      ],
      "metadata": {
        "id": "ERPxesf4c-8t"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn('word_lpad',lpad('word',10,'*')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2ia7i3cdKa-",
        "outputId": "a13da2de-cb86-404c-912d-0573abd6ee4e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----------+\n",
            "|   word|count| word_lpad|\n",
            "+-------+-----+----------+\n",
            "|Sixteen|    2|***Sixteen|\n",
            "|    two|    2|*******two|\n",
            "|  three|    1|*****three|\n",
            "|    one|    2|*******one|\n",
            "|    six|    1|*******six|\n",
            "|   nine|    2|******nine|\n",
            "+-------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn('word_rpad',rpad('word',10,'#')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sCCM2XJdXO9",
        "outputId": "e0fba1da-97a9-4d75-ebbb-8c1ec1d1cc58"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----------+\n",
            "|   word|count| word_rpad|\n",
            "+-------+-----+----------+\n",
            "|Sixteen|    2|Sixteen###|\n",
            "|    two|    2|two#######|\n",
            "|  three|    1|three#####|\n",
            "|    one|    2|one#######|\n",
            "|    six|    1|six#######|\n",
            "|   nine|    2|nine######|\n",
            "+-------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Convert the word lowercase to upper Case***"
      ],
      "metadata": {
        "id": "cz0v82qFd5Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import upper,lower\n",
        "df.withColumn('Word_upper',upper('word')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co-L2i1ednmT",
        "outputId": "d85516de-5a0d-49c3-89cc-5e6de3758804"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----------+\n",
            "|   word|count|Word_upper|\n",
            "+-------+-----+----------+\n",
            "|Sixteen|    2|   SIXTEEN|\n",
            "|    two|    2|       TWO|\n",
            "|  three|    1|     THREE|\n",
            "|    one|    2|       ONE|\n",
            "|    six|    1|       SIX|\n",
            "|   nine|    2|      NINE|\n",
            "+-------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert the word upper case to lower Case**"
      ],
      "metadata": {
        "id": "WOKcuL2MeCNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn('Word_lower',lower('word')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ0-K1xpeJSd",
        "outputId": "4bbdb620-9abc-4fcc-bb9c-3c280cce382c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----------+\n",
            "|   word|count|Word_lower|\n",
            "+-------+-----+----------+\n",
            "|Sixteen|    2|   sixteen|\n",
            "|    two|    2|       two|\n",
            "|  three|    1|     three|\n",
            "|    one|    2|       one|\n",
            "|    six|    1|       six|\n",
            "|   nine|    2|      nine|\n",
            "+-------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}